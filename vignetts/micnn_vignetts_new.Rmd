---
title: "Multiple instance based deep classification for mass spectrometry imaging"
author: "Dan Guo"
date: "5/26/2022"
output:
  #BiocStyle::html_document:
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
---

```{r style, echo=FALSE, results='asis'}
BiocStyle::markdown()
library(knitr)
knitr::knit_engines$set(python = reticulate::eng_python)
```

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(CardinalNN)
use_python("/usr/local/bin/python3")

```


# Introduction


*CardinalNN* is a side package of *Cardinal*. It provides both semi-supervised and fully-supervised deep learning methods for tissue classification using Mass Spectrometry Imaging (MSI) data. The neural network used as classifier is convolutional neural network (CNN). 

- _fully supervised_. It is the same as standard supervised classification and it is used when the ground-truth labels of pixels are known.

- _Multiple instance_. It is semi-supervised classification and it is used when only the ground-truth labels of tissues are known while no labels for pixels. The assumption is that positive tissues can contain both positive and negative pixels, while negative tissues can only contain negative pixels.

# Installation

*CardinalNN* development version can be installed via the *BiocManager* package.

```{r install, eval=FALSE}
install.packages("BiocManager")
BiocManager::install(version='devel')
BiocManager::install("CardinalNN")
```

The same function can be used to update *CardinalNN* and other Bioconductor packages.

Once installed, *CardinalNN* can be loaded with `library()`:

```{r library, eval=FALSE}
library(CardinalNN)
```

*CardinalNN* an R package but it relies on Python. Therefore it requires both R and Python to be installed. However, the Python codes are excuted backend and the usage of this package does not require writing any Python codes. Download python 3 from https://www.python.org/downloads/ and install. After installing python, install python package `DeepMSI`:

```{r, eval=FALSE}
git clone https://github.com/DanGuo1223/DeepMSI.git
sudo python3 setup.py install
```



# Load the training and testing datasets

The dataset is the same as XXX. We use TMA1 as the training set and TMA2 as the testing dataset.

```{r, echo = TRUE}
load('mse_train.rdata')
mse <- mse_train
load('mse_test.rdata')
mse_train <- mse_test
mse_test <- mse_train
image(mse,feature=1)
```

# Fully supervised training

Use `multipleInstanceCNN()` and specify the parameter `method` as 'fully_supervised' to perform standard supervised training on CNN. `num_epochs` is the iteration number of complete data passes. Other parameters such as `batch_size`, `lr`, and `optim`, please use `help('multipleInstanceCNN')`. The network structure and training processes will be printed out in R console.

```{r}
micnn_supervised <- multipleInstanceCNN(mse_train, mse_train$plabel, model_name = 'bladder_classifier1', method = 'fully_supervised', num_epochs = 1)
```
![Print out of the training in R console](console.png)

We can use `summary()` to summarize the trained model.

```{r}
summary(micnn_supervised)
```

Plot the predicted class.

```{r,  fig.height=2.5, fig.width=4, fig.align='center'}
image(micnn_supervised)
```

We can use `predict()` to predict the testing data using the trained model and visualize the results.

```{r, fig.height=2.5, fig.width=4, fig.align='center'}
micnn_supervised_predict <- predict(micnn_supervised, newx = mse_test, newy = mse_test$plabel)
image(micnn_supervised_predict)
```



Use `summary()` to summarize the performance of the trained model on testing data if the testing data has ground-truth labels.

```{r}
summary(micnn_supervised_predict)
```


Use `topFeatures()` to rank mass features by weights of explanability. `lime` is a local model-agnostic explanation method, for more detals, please refer to https://github.com/marcotcr/lime. `instance_id` is the id of pixel to be expalined in the testing data. `n` is the number of m/z features the method returned. `topFeatures()` returns a list of m/z features and their coefficient in lime fitting. The higher the absolute value of the coefficient is, more important the m/z feature is for the model prediction. Positive value means supporting the model prediction while negative value means contradicts the model prediction. 

```{r}
micnn_supervised_top <- topFeatures(micnn_supervised, train = train, test = test, method = 'lime', instance_id = 1, n = 10)
micnn_supervised_top
```


Plot barplot of the top features.

```{r, fig.height = 3, fig.width=6, fig.align='center'}
plot(micnn_supervised_top)
```

# Multiple instance based training

Use `multipleInstanceCNN()` and specify the parameter `method` as 'fully_supervised' to perform standard supervised training on CNN.

```{r}
micnn <- multipleInstanceCNN(mse_train, mse_train$tlabel, model_name = 'bladder_classifier2', method = 'multiple_instance', num_epochs = 2)
```

Summarize the trained model.

```{r}
summary(micnn)
```

Plot the predicted class.

```{r,  fig.height=2.5, fig.width=4, fig.align='center'}
image(micnn)
```

We can use `predict()` to predict the testing data using the trained model and visualize the results.

```{r, fig.height=2.5, fig.width=4, fig.align='center'}
micnn_predict <- predict(micnn, newx = mse_test, newy = mse_test$plabel)
image(micnn_predict)
```

Use `summary()` to summarize the performance of the trained model on testing data if the testing data has ground-truth labels.

```{r}
summary(micnn_predict)
```


Use `topFeatures()` to rank mass features by weights of explanability.

```{r}
micnn_top <- topFeatures(micnn, train = train, test = test, trainmethod = 'lime', n = 10)
micnn_top
```


Plot bar plot of the top features.

```{r, fig.height = 3, fig.width=6, fig.align='center'}
plot(micnn_top)
```

# Access the results data 

We can access the predictions using `resultData()'. The predictions contain the predicted classes and probabilities of each class.

```{r}
predicted_class <- resultData(micnn_predict)[[1]]$class
predicted_prob <- resultData(micnn_predict)[[1]]$probability
```


use it to subset the MSI data. Subsetting the pixels predicted as 0:

```{r}
mse_sub = mse_test[, predicted_class == 0]
mse_sub
```

Subsetting the pixels predicted as 1:


```{r}
mse_sub = mse_test[,predicted_class == 1]
mse_sub
```

We can visualize the predicted probabilities of the subset of pixels predicted as 1:

```{r}
image(mse_sub, predicted_prob[predicted_class==1]~x*y)
```


# Cross validation

When there's no enough samples to split into training and testing data, unlike reporting the accuracy on the testing data, we can report the average accuracy of cross validation. First, we create the x-fold (5-fold for example) split of the data:

```{r}
set.seed(1)
folds <- split(unique(mse_train$sample), sample(20, 5))
fold_dataframe <- data.frame(unlist(folds), c(rep(1, 4), rep(2, 4), rep(3, 4), rep (4,4), rep(5,4)))
colnames(fold_dataframe) <- c("patient", "folds")
rownames(fold_dataframe) <- NULL

p_df <- data.frame(mse_train$sample)
colnames(p_df) <- 'patient'
joint_df <- merge(fold_dataframe, p_df, by = 'patient')

mse_train$folds <- joint_df$folds

table(mse_train$folds)
```

Then we fit CNN models for different folds and summarize the accuracy, sensitivity, and specificty:

```{r}
micnn_cv <- crossValidate(mse_train, mse_train$plabel, 
                                .fun="multipleInstanceCNN", 
                                .fold=mse_train$folds)
summary(micnn_cv)
```

